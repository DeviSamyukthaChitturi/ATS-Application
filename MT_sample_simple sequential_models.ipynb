{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OLcp5M5QZX0x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Bidirectional, Concatenate, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('/content/Sample_dataset_for training.csv')\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne7k7GPzcuI9",
        "outputId": "9d4527c5-9f96-45aa-a0e2-ced7cf78bbbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Experience', 'Qualification', 'Tokenized_Job_Title',\n",
              "       'Tokenized_Job_Description', 'Tokenized_Skills', 'Tokenized_Resume',\n",
              "       'Resume_Score', 'Unnamed: 7', 'Unnamed: 8'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop empty columns and rows with missing values\n",
        "data = data.drop(columns=['Unnamed: 7', 'Unnamed: 8']).dropna()\n",
        "\n",
        "# Prepare text data for input (Tokenized text columns)\n",
        "text_columns = ['Tokenized_Job_Title', 'Tokenized_Job_Description', 'Tokenized_Skills', 'Tokenized_Resume']\n",
        "text_data = data[text_columns].agg(' '.join, axis=1)  # Combine columns into a single text field"
      ],
      "metadata": {
        "id": "_OZhCM8Tc0Fs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Padding for text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "X_text = pad_sequences(sequences, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "id": "4rD4DfK8c8YV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process `Experience` column\n",
        "experience_data = data['Experience'].values.reshape(-1, 1)\n",
        "scaler = StandardScaler()\n",
        "X_experience = scaler.fit_transform(experience_data)\n",
        "\n",
        "# Process `Qualification` column\n",
        "label_encoder = LabelEncoder()\n",
        "X_qualification = label_encoder.fit_transform(data['Qualification'])\n",
        "X_qualification = np.expand_dims(X_qualification, axis=1)  # Reshape for model input\n"
      ],
      "metadata": {
        "id": "MPy1Kzb4c-rE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target variable\n",
        "y = data['Resume_Score'].values\n",
        "\n",
        "# Train-test split\n",
        "X_text_train, X_text_test, X_exp_train, X_exp_test, X_qual_train, X_qual_test, y_train, y_test = train_test_split(\n",
        "    X_text, X_experience, X_qualification, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jGkyvTBOdAvd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture with combined features\n",
        "def build_combined_model(model_type='LSTM'):\n",
        "    # Text input branch\n",
        "    text_input = Input(shape=(max_len,), name='text_input')\n",
        "    embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len)(text_input)\n",
        "\n",
        "    if model_type == 'LSTM':\n",
        "        text_branch = Bidirectional(LSTM(64))(embedding)\n",
        "    elif model_type == 'GRU':\n",
        "        text_branch = Bidirectional(GRU(64))(embedding)\n",
        "    elif model_type == 'RNN':\n",
        "        text_branch = Flatten()(embedding)\n",
        "\n",
        "    # Numerical input branches\n",
        "    experience_input = Input(shape=(1,), name='experience_input')\n",
        "    qualification_input = Input(shape=(1,), name='qualification_input')\n",
        "\n",
        "    # Concatenate all branches\n",
        "    combined = Concatenate()([text_branch, experience_input, qualification_input])\n",
        "    dense = Dense(64, activation='relu')(combined)\n",
        "    output = Dense(1)(dense)  # Single output for Resume_Score\n",
        "\n",
        "    model = Model(inputs=[text_input, experience_input, qualification_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-Cks1BEWdD-l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each model\n",
        "models = ['LSTM', 'GRU', 'RNN']\n",
        "best_model = None\n",
        "best_mae = float('inf')"
      ],
      "metadata": {
        "id": "7lhyISLsdIB6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_type in models:\n",
        "    print(f\"\\nTraining {model_type} model...\")\n",
        "    model = build_combined_model(model_type=model_type)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        [X_text_train, X_exp_train, X_qual_train], y_train,\n",
        "        epochs=10, batch_size=32, validation_split=0.1, verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    y_pred = model.predict([X_text_test, X_exp_test, X_qual_test])\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"{model_type} Model - MAE: {mae}, MSE: {mse}\")\n",
        "\n",
        "    # Track the best model based on MAE\n",
        "    if mae < best_mae:\n",
        "        best_mae = mae\n",
        "        best_model = model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw0NDYkBdLIl",
        "outputId": "dd1c71c1-de7f-4592-9c17-eb070050db6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 3293.8359 - mae: 56.0794 - val_loss: 2872.1426 - val_mae: 52.7044\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - loss: 3074.9766 - mae: 53.8878 - val_loss: 2201.9919 - val_mae: 45.9019\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 2233.2051 - mae: 45.6896 - val_loss: 1456.7887 - val_mae: 36.9044\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - loss: 1429.3483 - mae: 35.6281 - val_loss: 776.8044 - val_mae: 26.1171\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 810.5490 - mae: 25.4330 - val_loss: 323.3853 - val_mae: 15.1822\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 356.2679 - mae: 14.8220 - val_loss: 122.6413 - val_mae: 8.2752\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 199.7964 - mae: 11.5198 - val_loss: 98.5215 - val_mae: 8.0200\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 158.3125 - mae: 10.8011 - val_loss: 118.8310 - val_mae: 8.8517\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 166.0558 - mae: 11.0229 - val_loss: 117.3249 - val_mae: 8.7842\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 154.4182 - mae: 10.7026 - val_loss: 105.5908 - val_mae: 8.2756\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step\n",
            "LSTM Model - MAE: 9.834689044952393, MSE: 130.5168052795616\n",
            "\n",
            "Training GRU model...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 3360.1853 - mae: 56.7080 - val_loss: 3034.7974 - val_mae: 54.2149\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 3251.5713 - mae: 55.5523 - val_loss: 2583.0244 - val_mae: 49.8675\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 2692.3027 - mae: 50.1341 - val_loss: 1539.4325 - val_mae: 37.9761\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 1587.9771 - mae: 37.6539 - val_loss: 731.2272 - val_mae: 25.2082\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 751.7014 - mae: 24.2793 - val_loss: 288.2708 - val_mae: 14.0475\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - loss: 360.8160 - mae: 14.9486 - val_loss: 109.2895 - val_mae: 7.9648\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - loss: 168.4593 - mae: 10.6875 - val_loss: 104.1758 - val_mae: 8.2655\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 162.9388 - mae: 11.0188 - val_loss: 125.2302 - val_mae: 9.1559\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - loss: 169.3311 - mae: 11.2557 - val_loss: 116.9072 - val_mae: 8.7184\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - loss: 159.0722 - mae: 10.8317 - val_loss: 103.8621 - val_mae: 8.2600\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 738ms/step\n",
            "GRU Model - MAE: 9.877690315246582, MSE: 131.28221284236534\n",
            "\n",
            "Training RNN model...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - loss: 2227.0874 - mae: 42.2113 - val_loss: 445.2667 - val_mae: 19.2815\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 521.7360 - mae: 19.2968 - val_loss: 327.1376 - val_mae: 15.6212\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - loss: 296.3337 - mae: 14.1620 - val_loss: 204.2188 - val_mae: 11.6451\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - loss: 213.4550 - mae: 11.6464 - val_loss: 120.0467 - val_mae: 8.9433\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 141.4822 - mae: 9.2649 - val_loss: 78.0282 - val_mae: 7.0577\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - loss: 102.1929 - mae: 8.1416 - val_loss: 76.6586 - val_mae: 6.9332\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - loss: 82.0646 - mae: 7.2613 - val_loss: 84.9606 - val_mae: 7.5388\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - loss: 77.9420 - mae: 6.6806 - val_loss: 71.7537 - val_mae: 6.9235\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 291ms/step - loss: 52.7269 - mae: 5.6874 - val_loss: 73.6376 - val_mae: 7.1359\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256ms/step - loss: 41.4552 - mae: 5.0949 - val_loss: 67.3810 - val_mae: 6.8695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7be08503ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7be08503ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "RNN Model - MAE: 8.120315074920654, MSE: 111.7302003038316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBest model based on MAE:\", best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWk-FnR2dNNU",
        "outputId": "7ac3e4f3-f24a-46e3-945e-0139fbd14ae7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model based on MAE: <Functional name=functional_2, built=True>\n"
          ]
        }
      ]
    }
  ]
}